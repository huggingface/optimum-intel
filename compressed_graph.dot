strict digraph  {
"0 /nncf_model_input_0";
"1 /nncf_model_input_1";
"2 GPT2LMHeadModel/GPT2Model[transformer]/view_0";
"3 GPT2LMHeadModel/GPT2Model[transformer]/view_1";
"4 GPT2LMHeadModel/GPT2Model[transformer]/__getitem___0";
"5 GPT2LMHeadModel/GPT2Model[transformer]/NNCFEmbedding[wte]/embedding_0";
"6 GPT2LMHeadModel/GPT2Model[transformer]/NNCFEmbedding[wpe]/embedding_0";
"7 GPT2LMHeadModel/GPT2Model[transformer]/__add___0";
"8 GPT2LMHeadModel/GPT2Model[transformer]/Dropout[drop]/dropout_0";
"9 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/NNCFLayerNorm[ln_1]/layer_norm_0";
"10 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/NNCFLayerNorm[ln_1]/AsymmetricQuantizer/asymmetric_quantize_0";
"11 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_attn]/view_0";
"12 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_attn]/addmm_0";
"13 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_attn]/view_1";
"14 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/split_0";
"15 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_0";
"16 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/view_0";
"17 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/permute_0";
"18 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_1";
"19 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/view_1";
"20 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/permute_1";
"21 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/view_2";
"22 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/permute_2";
"23 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/transpose_0";
"24 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/matmul_0";
"25 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/full_0";
"26 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/__truediv___0";
"27 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/full_1";
"28 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/where_0";
"29 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/__add___0";
"30 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/softmax_0";
"31 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/type_0";
"32 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Dropout[attn_dropout]/dropout_0";
"33 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/matmul_1";
"34 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/AsymmetricQuantizer/asymmetric_quantize_0";
"35 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/permute_3";
"36 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/contiguous_0";
"37 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/view_3";
"38 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_proj]/view_0";
"39 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_proj]/addmm_0";
"40 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_proj]/view_1";
"41 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Dropout[resid_dropout]/dropout_0";
"42 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/__add___0";
"43 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/NNCFLayerNorm[ln_2]/layer_norm_0";
"44 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/NNCFLayerNorm[ln_2]/AsymmetricQuantizer/asymmetric_quantize_0";
"45 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_fc]/view_0";
"46 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_fc]/addmm_0";
"47 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1";
"48 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_0";
"49 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___0";
"50 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_1";
"51 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_2";
"52 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/pow_0";
"53 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_3";
"54 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___1";
"55 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0";
"56 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_4";
"57 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___2";
"58 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_5";
"59 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/tanh_0";
"60 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__radd___0";
"61 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_6";
"62 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0";
"63 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_7";
"64 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_proj]/view_0";
"65 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_proj]/addmm_0";
"66 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_proj]/view_1";
"67 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Dropout[dropout]/dropout_0";
"68 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/__add___1";
"69 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/NNCFLayerNorm[ln_1]/layer_norm_0";
"70 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/NNCFLayerNorm[ln_1]/AsymmetricQuantizer/asymmetric_quantize_0";
"71 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_attn]/view_0";
"72 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_attn]/addmm_0";
"73 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_attn]/view_1";
"74 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/split_0";
"75 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_0";
"76 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/view_0";
"77 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/permute_0";
"78 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_1";
"79 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/view_1";
"80 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/permute_1";
"81 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/view_2";
"82 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/permute_2";
"83 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/transpose_0";
"84 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/matmul_0";
"85 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/full_0";
"86 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/__truediv___0";
"87 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/full_1";
"88 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/where_0";
"89 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/__add___0";
"90 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/softmax_0";
"91 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/type_0";
"92 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Dropout[attn_dropout]/dropout_0";
"93 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/matmul_1";
"94 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/AsymmetricQuantizer/asymmetric_quantize_0";
"95 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/permute_3";
"96 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/contiguous_0";
"97 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/view_3";
"98 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_proj]/view_0";
"99 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_proj]/addmm_0";
"100 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_proj]/view_1";
"101 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Dropout[resid_dropout]/dropout_0";
"102 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/__add___0";
"103 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/NNCFLayerNorm[ln_2]/layer_norm_0";
"104 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/NNCFLayerNorm[ln_2]/AsymmetricQuantizer/asymmetric_quantize_0";
"105 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_fc]/view_0";
"106 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_fc]/addmm_0";
"107 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1";
"108 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_0";
"109 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___0";
"110 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_1";
"111 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_2";
"112 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/pow_0";
"113 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_3";
"114 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___1";
"115 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0";
"116 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_4";
"117 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___2";
"118 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_5";
"119 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/tanh_0";
"120 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__radd___0";
"121 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_6";
"122 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0";
"123 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_7";
"124 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_proj]/view_0";
"125 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_proj]/addmm_0";
"126 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_proj]/view_1";
"127 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Dropout[dropout]/dropout_0";
"128 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/__add___1";
"129 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/NNCFLayerNorm[ln_1]/layer_norm_0";
"130 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/NNCFLayerNorm[ln_1]/AsymmetricQuantizer/asymmetric_quantize_0";
"131 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_attn]/view_0";
"132 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_attn]/addmm_0";
"133 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_attn]/view_1";
"134 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/split_0";
"135 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_0";
"136 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/view_0";
"137 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/permute_0";
"138 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_1";
"139 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/view_1";
"140 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/permute_1";
"141 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/view_2";
"142 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/permute_2";
"143 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/transpose_0";
"144 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/matmul_0";
"145 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/full_0";
"146 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/__truediv___0";
"147 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/full_1";
"148 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/where_0";
"149 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/__add___0";
"150 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/softmax_0";
"151 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/type_0";
"152 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Dropout[attn_dropout]/dropout_0";
"153 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/matmul_1";
"154 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/AsymmetricQuantizer/asymmetric_quantize_0";
"155 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/permute_3";
"156 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/contiguous_0";
"157 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/view_3";
"158 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_proj]/view_0";
"159 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_proj]/addmm_0";
"160 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_proj]/view_1";
"161 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Dropout[resid_dropout]/dropout_0";
"162 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/__add___0";
"163 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/NNCFLayerNorm[ln_2]/layer_norm_0";
"164 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/NNCFLayerNorm[ln_2]/AsymmetricQuantizer/asymmetric_quantize_0";
"165 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_fc]/view_0";
"166 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_fc]/addmm_0";
"167 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1";
"168 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_0";
"169 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___0";
"170 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_1";
"171 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_2";
"172 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/pow_0";
"173 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_3";
"174 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___1";
"175 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0";
"176 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_4";
"177 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___2";
"178 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_5";
"179 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/tanh_0";
"180 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__radd___0";
"181 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_6";
"182 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0";
"183 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_7";
"184 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_proj]/view_0";
"185 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_proj]/addmm_0";
"186 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_proj]/view_1";
"187 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Dropout[dropout]/dropout_0";
"188 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/__add___1";
"189 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/NNCFLayerNorm[ln_1]/layer_norm_0";
"190 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/NNCFLayerNorm[ln_1]/AsymmetricQuantizer/asymmetric_quantize_0";
"191 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_attn]/view_0";
"192 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_attn]/addmm_0";
"193 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_attn]/view_1";
"194 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/split_0";
"195 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_0";
"196 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/view_0";
"197 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/permute_0";
"198 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_1";
"199 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/view_1";
"200 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/permute_1";
"201 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/view_2";
"202 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/permute_2";
"203 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/transpose_0";
"204 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/matmul_0";
"205 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/full_0";
"206 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/__truediv___0";
"207 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/full_1";
"208 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/where_0";
"209 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/__add___0";
"210 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/softmax_0";
"211 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/type_0";
"212 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Dropout[attn_dropout]/dropout_0";
"213 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/matmul_1";
"214 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/AsymmetricQuantizer/asymmetric_quantize_0";
"215 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/permute_3";
"216 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/contiguous_0";
"217 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/view_3";
"218 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_proj]/view_0";
"219 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_proj]/addmm_0";
"220 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_proj]/view_1";
"221 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Dropout[resid_dropout]/dropout_0";
"222 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/__add___0";
"223 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/NNCFLayerNorm[ln_2]/layer_norm_0";
"224 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/NNCFLayerNorm[ln_2]/AsymmetricQuantizer/asymmetric_quantize_0";
"225 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_fc]/view_0";
"226 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_fc]/addmm_0";
"227 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1";
"228 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_0";
"229 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___0";
"230 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_1";
"231 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_2";
"232 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/pow_0";
"233 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_3";
"234 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___1";
"235 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0";
"236 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_4";
"237 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___2";
"238 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_5";
"239 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/tanh_0";
"240 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__radd___0";
"241 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_6";
"242 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0";
"243 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_7";
"244 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_proj]/view_0";
"245 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_proj]/addmm_0";
"246 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_proj]/view_1";
"247 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Dropout[dropout]/dropout_0";
"248 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/__add___1";
"249 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/NNCFLayerNorm[ln_1]/layer_norm_0";
"250 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/NNCFLayerNorm[ln_1]/AsymmetricQuantizer/asymmetric_quantize_0";
"251 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_attn]/view_0";
"252 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_attn]/addmm_0";
"253 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_attn]/view_1";
"254 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/split_0";
"255 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_0";
"256 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/view_0";
"257 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/permute_0";
"258 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_1";
"259 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/view_1";
"260 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/permute_1";
"261 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/view_2";
"262 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/permute_2";
"263 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/transpose_0";
"264 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/matmul_0";
"265 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/full_0";
"266 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/__truediv___0";
"267 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/full_1";
"268 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/where_0";
"269 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/__add___0";
"270 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/softmax_0";
"271 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/type_0";
"272 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Dropout[attn_dropout]/dropout_0";
"273 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/matmul_1";
"274 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/AsymmetricQuantizer/asymmetric_quantize_0";
"275 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/permute_3";
"276 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/contiguous_0";
"277 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/view_3";
"278 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_proj]/view_0";
"279 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_proj]/addmm_0";
"280 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_proj]/view_1";
"281 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Dropout[resid_dropout]/dropout_0";
"282 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/__add___0";
"283 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/NNCFLayerNorm[ln_2]/layer_norm_0";
"284 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/NNCFLayerNorm[ln_2]/AsymmetricQuantizer/asymmetric_quantize_0";
"285 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_fc]/view_0";
"286 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_fc]/addmm_0";
"287 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1";
"288 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_0";
"289 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___0";
"290 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_1";
"291 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_2";
"292 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/pow_0";
"293 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_3";
"294 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___1";
"295 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0";
"296 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_4";
"297 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___2";
"298 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_5";
"299 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/tanh_0";
"300 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__radd___0";
"301 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_6";
"302 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0";
"303 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_7";
"304 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_proj]/view_0";
"305 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_proj]/addmm_0";
"306 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_proj]/view_1";
"307 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Dropout[dropout]/dropout_0";
"308 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/__add___1";
"309 GPT2LMHeadModel/GPT2Model[transformer]/NNCFLayerNorm[ln_f]/layer_norm_0";
"310 GPT2LMHeadModel/GPT2Model[transformer]/NNCFLayerNorm[ln_f]/AsymmetricQuantizer/asymmetric_quantize_0";
"311 GPT2LMHeadModel/GPT2Model[transformer]/view_2";
"312 GPT2LMHeadModel/NNCFLinear[lm_head]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"313 GPT2LMHeadModel/NNCFLinear[lm_head]/linear_0";
"314 /nncf_model_output_0";
"315 /nncf_model_output_1";
"316 /nncf_model_output_2";
"317 /nncf_model_output_3";
"318 /nncf_model_output_4";
"319 /nncf_model_output_5";
"320 /nncf_model_output_6";
"321 /nncf_model_output_7";
"322 /nncf_model_output_8";
"323 /nncf_model_output_9";
"324 /nncf_model_output_10";
"0 /nncf_model_input_0" -> "3 GPT2LMHeadModel/GPT2Model[transformer]/view_1"  [label="(1, 128) \n0 -> 0", style=dashed];
"1 /nncf_model_input_1" -> "2 GPT2LMHeadModel/GPT2Model[transformer]/view_0"  [label="(1, 128) \n0 -> 0", style=dashed];
"2 GPT2LMHeadModel/GPT2Model[transformer]/view_0" -> "5 GPT2LMHeadModel/GPT2Model[transformer]/NNCFEmbedding[wte]/embedding_0"  [label="(1, 128) \n0 -> 0", style=dashed];
"3 GPT2LMHeadModel/GPT2Model[transformer]/view_1" -> "4 GPT2LMHeadModel/GPT2Model[transformer]/__getitem___0"  [label="(1, 128) \n0 -> 0", style=dashed];
"5 GPT2LMHeadModel/GPT2Model[transformer]/NNCFEmbedding[wte]/embedding_0" -> "7 GPT2LMHeadModel/GPT2Model[transformer]/__add___0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"6 GPT2LMHeadModel/GPT2Model[transformer]/NNCFEmbedding[wpe]/embedding_0" -> "7 GPT2LMHeadModel/GPT2Model[transformer]/__add___0"  [label="(1, 128, 32) \n0 -> 1", style=solid];
"7 GPT2LMHeadModel/GPT2Model[transformer]/__add___0" -> "8 GPT2LMHeadModel/GPT2Model[transformer]/Dropout[drop]/dropout_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"8 GPT2LMHeadModel/GPT2Model[transformer]/Dropout[drop]/dropout_0" -> "9 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/NNCFLayerNorm[ln_1]/layer_norm_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"8 GPT2LMHeadModel/GPT2Model[transformer]/Dropout[drop]/dropout_0" -> "42 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/__add___0"  [label="(1, 128, 32) \n0 -> 1", style=solid];
"9 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/NNCFLayerNorm[ln_1]/layer_norm_0" -> "10 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/NNCFLayerNorm[ln_1]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"10 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/NNCFLayerNorm[ln_1]/AsymmetricQuantizer/asymmetric_quantize_0" -> "11 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_attn]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"11 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_attn]/view_0" -> "12 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_attn]/addmm_0"  [label="(128, 32) \n0 -> 1", style=solid];
"12 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_attn]/addmm_0" -> "13 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_attn]/view_1"  [label="(128, 96) \n0 -> 0", style=solid];
"13 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_attn]/view_1" -> "14 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/split_0"  [label="(1, 128, 96) \n0 -> 0", style=solid];
"14 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/split_0" -> "15 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"14 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/split_0" -> "18 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_1"  [label="(1, 128, 32) \n1 -> 0", style=solid];
"14 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/split_0" -> "21 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/view_2"  [label="(1, 128, 32) \n2 -> 0", style=solid];
"15 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_0" -> "16 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"16 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/view_0" -> "17 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/permute_0"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"17 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/permute_0" -> "24 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/matmul_0"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"18 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_1" -> "19 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/view_1"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"19 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/view_1" -> "20 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/permute_1"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"20 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/permute_1" -> "23 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/transpose_0"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"20 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/permute_1" -> "314 /nncf_model_output_0"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"21 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/view_2" -> "22 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/permute_2"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"22 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/permute_2" -> "33 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/matmul_1"  [label="(1, 4, 128, 8) \n0 -> 1", style=solid];
"22 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/permute_2" -> "315 /nncf_model_output_1"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"23 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/transpose_0" -> "24 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/matmul_0"  [label="(1, 4, 8, 128) \n0 -> 1", style=solid];
"24 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/matmul_0" -> "26 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/__truediv___0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"25 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/full_0" -> "26 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/__truediv___0"  [label="() \n0 -> 1", style=solid];
"26 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/__truediv___0" -> "28 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/where_0"  [label="(1, 4, 128, 128) \n0 -> 1", style=solid];
"27 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/full_1" -> "28 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/where_0"  [label="() \n0 -> 2", style=solid];
"28 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/where_0" -> "29 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/__add___0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"29 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/__add___0" -> "30 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/softmax_0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"30 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/softmax_0" -> "31 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/type_0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"31 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/type_0" -> "32 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Dropout[attn_dropout]/dropout_0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"32 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Dropout[attn_dropout]/dropout_0" -> "33 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/matmul_1"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"33 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/matmul_1" -> "34 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"34 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "35 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/permute_3"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"35 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/permute_3" -> "36 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/contiguous_0"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"36 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/contiguous_0" -> "37 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/view_3"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"37 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/view_3" -> "38 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_proj]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"38 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_proj]/view_0" -> "39 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_proj]/addmm_0"  [label="(128, 32) \n0 -> 1", style=solid];
"39 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_proj]/addmm_0" -> "40 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_proj]/view_1"  [label="(128, 32) \n0 -> 0", style=solid];
"40 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Conv1D[c_proj]/view_1" -> "41 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Dropout[resid_dropout]/dropout_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"41 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2Attention[attn]/Dropout[resid_dropout]/dropout_0" -> "42 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/__add___0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"42 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/__add___0" -> "43 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/NNCFLayerNorm[ln_2]/layer_norm_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"42 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/__add___0" -> "68 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/__add___1"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"43 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/NNCFLayerNorm[ln_2]/layer_norm_0" -> "44 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/NNCFLayerNorm[ln_2]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"44 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/NNCFLayerNorm[ln_2]/AsymmetricQuantizer/asymmetric_quantize_0" -> "45 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_fc]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"45 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_fc]/view_0" -> "46 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_fc]/addmm_0"  [label="(128, 32) \n0 -> 1", style=solid];
"46 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_fc]/addmm_0" -> "47 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1"  [label="(128, 128) \n0 -> 0", style=solid];
"47 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1" -> "48 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"47 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1" -> "51 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_2"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"47 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1" -> "55 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"48 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_0" -> "49 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"49 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___0" -> "50 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_1"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"50 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_1" -> "62 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"51 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_2" -> "52 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/pow_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"52 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/pow_0" -> "53 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_3"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"53 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_3" -> "54 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___1"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"54 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___1" -> "55 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0"  [label="(1, 128, 128) \n0 -> 1", style=solid];
"55 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0" -> "56 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_4"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"56 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_4" -> "57 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___2"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"57 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___2" -> "58 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_5"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"58 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_5" -> "59 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/tanh_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"59 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/tanh_0" -> "60 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__radd___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"60 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__radd___0" -> "61 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_6"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"61 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_6" -> "62 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0"  [label="(1, 128, 128) \n0 -> 1", style=solid];
"62 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0" -> "63 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_7"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"63 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_7" -> "64 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_proj]/view_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"64 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_proj]/view_0" -> "65 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_proj]/addmm_0"  [label="(128, 128) \n0 -> 1", style=solid];
"65 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_proj]/addmm_0" -> "66 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_proj]/view_1"  [label="(128, 32) \n0 -> 0", style=solid];
"66 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Conv1D[c_proj]/view_1" -> "67 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Dropout[dropout]/dropout_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"67 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/GPT2MLP[mlp]/Dropout[dropout]/dropout_0" -> "68 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/__add___1"  [label="(1, 128, 32) \n0 -> 1", style=solid];
"68 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/__add___1" -> "69 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/NNCFLayerNorm[ln_1]/layer_norm_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"68 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[0]/__add___1" -> "102 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/__add___0"  [label="(1, 128, 32) \n0 -> 1", style=solid];
"69 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/NNCFLayerNorm[ln_1]/layer_norm_0" -> "70 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/NNCFLayerNorm[ln_1]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"70 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/NNCFLayerNorm[ln_1]/AsymmetricQuantizer/asymmetric_quantize_0" -> "71 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_attn]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"71 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_attn]/view_0" -> "72 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_attn]/addmm_0"  [label="(128, 32) \n0 -> 1", style=solid];
"72 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_attn]/addmm_0" -> "73 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_attn]/view_1"  [label="(128, 96) \n0 -> 0", style=solid];
"73 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_attn]/view_1" -> "74 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/split_0"  [label="(1, 128, 96) \n0 -> 0", style=solid];
"74 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/split_0" -> "75 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"74 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/split_0" -> "78 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_1"  [label="(1, 128, 32) \n1 -> 0", style=solid];
"74 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/split_0" -> "81 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/view_2"  [label="(1, 128, 32) \n2 -> 0", style=solid];
"75 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_0" -> "76 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"76 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/view_0" -> "77 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/permute_0"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"77 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/permute_0" -> "84 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/matmul_0"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"78 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_1" -> "79 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/view_1"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"79 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/view_1" -> "80 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/permute_1"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"80 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/permute_1" -> "83 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/transpose_0"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"80 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/permute_1" -> "316 /nncf_model_output_2"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"81 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/view_2" -> "82 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/permute_2"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"82 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/permute_2" -> "93 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/matmul_1"  [label="(1, 4, 128, 8) \n0 -> 1", style=solid];
"82 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/permute_2" -> "317 /nncf_model_output_3"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"83 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/transpose_0" -> "84 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/matmul_0"  [label="(1, 4, 8, 128) \n0 -> 1", style=solid];
"84 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/matmul_0" -> "86 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/__truediv___0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"85 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/full_0" -> "86 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/__truediv___0"  [label="() \n0 -> 1", style=solid];
"86 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/__truediv___0" -> "88 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/where_0"  [label="(1, 4, 128, 128) \n0 -> 1", style=solid];
"87 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/full_1" -> "88 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/where_0"  [label="() \n0 -> 2", style=solid];
"88 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/where_0" -> "89 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/__add___0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"89 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/__add___0" -> "90 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/softmax_0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"90 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/softmax_0" -> "91 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/type_0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"91 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/type_0" -> "92 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Dropout[attn_dropout]/dropout_0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"92 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Dropout[attn_dropout]/dropout_0" -> "93 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/matmul_1"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"93 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/matmul_1" -> "94 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"94 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "95 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/permute_3"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"95 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/permute_3" -> "96 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/contiguous_0"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"96 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/contiguous_0" -> "97 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/view_3"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"97 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/view_3" -> "98 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_proj]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"98 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_proj]/view_0" -> "99 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_proj]/addmm_0"  [label="(128, 32) \n0 -> 1", style=solid];
"99 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_proj]/addmm_0" -> "100 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_proj]/view_1"  [label="(128, 32) \n0 -> 0", style=solid];
"100 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Conv1D[c_proj]/view_1" -> "101 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Dropout[resid_dropout]/dropout_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"101 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2Attention[attn]/Dropout[resid_dropout]/dropout_0" -> "102 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/__add___0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"102 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/__add___0" -> "103 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/NNCFLayerNorm[ln_2]/layer_norm_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"102 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/__add___0" -> "128 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/__add___1"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"103 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/NNCFLayerNorm[ln_2]/layer_norm_0" -> "104 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/NNCFLayerNorm[ln_2]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"104 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/NNCFLayerNorm[ln_2]/AsymmetricQuantizer/asymmetric_quantize_0" -> "105 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_fc]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"105 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_fc]/view_0" -> "106 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_fc]/addmm_0"  [label="(128, 32) \n0 -> 1", style=solid];
"106 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_fc]/addmm_0" -> "107 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1"  [label="(128, 128) \n0 -> 0", style=solid];
"107 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1" -> "108 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"107 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1" -> "111 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_2"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"107 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1" -> "115 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"108 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_0" -> "109 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"109 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___0" -> "110 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_1"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"110 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_1" -> "122 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"111 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_2" -> "112 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/pow_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"112 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/pow_0" -> "113 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_3"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"113 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_3" -> "114 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___1"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"114 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___1" -> "115 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0"  [label="(1, 128, 128) \n0 -> 1", style=solid];
"115 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0" -> "116 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_4"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"116 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_4" -> "117 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___2"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"117 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___2" -> "118 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_5"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"118 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_5" -> "119 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/tanh_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"119 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/tanh_0" -> "120 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__radd___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"120 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__radd___0" -> "121 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_6"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"121 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_6" -> "122 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0"  [label="(1, 128, 128) \n0 -> 1", style=solid];
"122 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0" -> "123 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_7"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"123 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_7" -> "124 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_proj]/view_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"124 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_proj]/view_0" -> "125 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_proj]/addmm_0"  [label="(128, 128) \n0 -> 1", style=solid];
"125 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_proj]/addmm_0" -> "126 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_proj]/view_1"  [label="(128, 32) \n0 -> 0", style=solid];
"126 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Conv1D[c_proj]/view_1" -> "127 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Dropout[dropout]/dropout_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"127 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/GPT2MLP[mlp]/Dropout[dropout]/dropout_0" -> "128 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/__add___1"  [label="(1, 128, 32) \n0 -> 1", style=solid];
"128 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/__add___1" -> "129 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/NNCFLayerNorm[ln_1]/layer_norm_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"128 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[1]/__add___1" -> "162 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/__add___0"  [label="(1, 128, 32) \n0 -> 1", style=solid];
"129 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/NNCFLayerNorm[ln_1]/layer_norm_0" -> "130 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/NNCFLayerNorm[ln_1]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"130 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/NNCFLayerNorm[ln_1]/AsymmetricQuantizer/asymmetric_quantize_0" -> "131 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_attn]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"131 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_attn]/view_0" -> "132 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_attn]/addmm_0"  [label="(128, 32) \n0 -> 1", style=solid];
"132 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_attn]/addmm_0" -> "133 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_attn]/view_1"  [label="(128, 96) \n0 -> 0", style=solid];
"133 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_attn]/view_1" -> "134 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/split_0"  [label="(1, 128, 96) \n0 -> 0", style=solid];
"134 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/split_0" -> "135 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"134 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/split_0" -> "138 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_1"  [label="(1, 128, 32) \n1 -> 0", style=solid];
"134 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/split_0" -> "141 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/view_2"  [label="(1, 128, 32) \n2 -> 0", style=solid];
"135 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_0" -> "136 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"136 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/view_0" -> "137 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/permute_0"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"137 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/permute_0" -> "144 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/matmul_0"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"138 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_1" -> "139 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/view_1"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"139 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/view_1" -> "140 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/permute_1"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"140 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/permute_1" -> "143 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/transpose_0"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"140 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/permute_1" -> "318 /nncf_model_output_4"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"141 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/view_2" -> "142 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/permute_2"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"142 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/permute_2" -> "153 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/matmul_1"  [label="(1, 4, 128, 8) \n0 -> 1", style=solid];
"142 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/permute_2" -> "319 /nncf_model_output_5"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"143 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/transpose_0" -> "144 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/matmul_0"  [label="(1, 4, 8, 128) \n0 -> 1", style=solid];
"144 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/matmul_0" -> "146 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/__truediv___0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"145 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/full_0" -> "146 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/__truediv___0"  [label="() \n0 -> 1", style=solid];
"146 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/__truediv___0" -> "148 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/where_0"  [label="(1, 4, 128, 128) \n0 -> 1", style=solid];
"147 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/full_1" -> "148 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/where_0"  [label="() \n0 -> 2", style=solid];
"148 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/where_0" -> "149 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/__add___0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"149 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/__add___0" -> "150 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/softmax_0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"150 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/softmax_0" -> "151 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/type_0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"151 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/type_0" -> "152 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Dropout[attn_dropout]/dropout_0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"152 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Dropout[attn_dropout]/dropout_0" -> "153 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/matmul_1"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"153 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/matmul_1" -> "154 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"154 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "155 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/permute_3"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"155 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/permute_3" -> "156 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/contiguous_0"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"156 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/contiguous_0" -> "157 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/view_3"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"157 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/view_3" -> "158 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_proj]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"158 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_proj]/view_0" -> "159 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_proj]/addmm_0"  [label="(128, 32) \n0 -> 1", style=solid];
"159 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_proj]/addmm_0" -> "160 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_proj]/view_1"  [label="(128, 32) \n0 -> 0", style=solid];
"160 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Conv1D[c_proj]/view_1" -> "161 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Dropout[resid_dropout]/dropout_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"161 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2Attention[attn]/Dropout[resid_dropout]/dropout_0" -> "162 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/__add___0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"162 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/__add___0" -> "163 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/NNCFLayerNorm[ln_2]/layer_norm_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"162 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/__add___0" -> "188 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/__add___1"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"163 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/NNCFLayerNorm[ln_2]/layer_norm_0" -> "164 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/NNCFLayerNorm[ln_2]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"164 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/NNCFLayerNorm[ln_2]/AsymmetricQuantizer/asymmetric_quantize_0" -> "165 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_fc]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"165 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_fc]/view_0" -> "166 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_fc]/addmm_0"  [label="(128, 32) \n0 -> 1", style=solid];
"166 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_fc]/addmm_0" -> "167 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1"  [label="(128, 128) \n0 -> 0", style=solid];
"167 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1" -> "168 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"167 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1" -> "171 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_2"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"167 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1" -> "175 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"168 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_0" -> "169 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"169 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___0" -> "170 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_1"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"170 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_1" -> "182 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"171 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_2" -> "172 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/pow_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"172 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/pow_0" -> "173 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_3"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"173 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_3" -> "174 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___1"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"174 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___1" -> "175 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0"  [label="(1, 128, 128) \n0 -> 1", style=solid];
"175 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0" -> "176 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_4"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"176 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_4" -> "177 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___2"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"177 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___2" -> "178 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_5"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"178 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_5" -> "179 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/tanh_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"179 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/tanh_0" -> "180 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__radd___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"180 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__radd___0" -> "181 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_6"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"181 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_6" -> "182 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0"  [label="(1, 128, 128) \n0 -> 1", style=solid];
"182 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0" -> "183 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_7"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"183 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_7" -> "184 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_proj]/view_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"184 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_proj]/view_0" -> "185 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_proj]/addmm_0"  [label="(128, 128) \n0 -> 1", style=solid];
"185 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_proj]/addmm_0" -> "186 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_proj]/view_1"  [label="(128, 32) \n0 -> 0", style=solid];
"186 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Conv1D[c_proj]/view_1" -> "187 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Dropout[dropout]/dropout_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"187 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/GPT2MLP[mlp]/Dropout[dropout]/dropout_0" -> "188 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/__add___1"  [label="(1, 128, 32) \n0 -> 1", style=solid];
"188 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/__add___1" -> "189 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/NNCFLayerNorm[ln_1]/layer_norm_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"188 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[2]/__add___1" -> "222 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/__add___0"  [label="(1, 128, 32) \n0 -> 1", style=solid];
"189 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/NNCFLayerNorm[ln_1]/layer_norm_0" -> "190 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/NNCFLayerNorm[ln_1]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"190 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/NNCFLayerNorm[ln_1]/AsymmetricQuantizer/asymmetric_quantize_0" -> "191 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_attn]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"191 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_attn]/view_0" -> "192 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_attn]/addmm_0"  [label="(128, 32) \n0 -> 1", style=solid];
"192 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_attn]/addmm_0" -> "193 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_attn]/view_1"  [label="(128, 96) \n0 -> 0", style=solid];
"193 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_attn]/view_1" -> "194 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/split_0"  [label="(1, 128, 96) \n0 -> 0", style=solid];
"194 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/split_0" -> "195 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"194 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/split_0" -> "198 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_1"  [label="(1, 128, 32) \n1 -> 0", style=solid];
"194 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/split_0" -> "201 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/view_2"  [label="(1, 128, 32) \n2 -> 0", style=solid];
"195 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_0" -> "196 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"196 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/view_0" -> "197 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/permute_0"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"197 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/permute_0" -> "204 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/matmul_0"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"198 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_1" -> "199 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/view_1"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"199 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/view_1" -> "200 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/permute_1"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"200 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/permute_1" -> "203 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/transpose_0"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"200 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/permute_1" -> "320 /nncf_model_output_6"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"201 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/view_2" -> "202 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/permute_2"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"202 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/permute_2" -> "213 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/matmul_1"  [label="(1, 4, 128, 8) \n0 -> 1", style=solid];
"202 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/permute_2" -> "321 /nncf_model_output_7"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"203 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/transpose_0" -> "204 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/matmul_0"  [label="(1, 4, 8, 128) \n0 -> 1", style=solid];
"204 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/matmul_0" -> "206 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/__truediv___0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"205 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/full_0" -> "206 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/__truediv___0"  [label="() \n0 -> 1", style=solid];
"206 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/__truediv___0" -> "208 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/where_0"  [label="(1, 4, 128, 128) \n0 -> 1", style=solid];
"207 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/full_1" -> "208 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/where_0"  [label="() \n0 -> 2", style=solid];
"208 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/where_0" -> "209 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/__add___0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"209 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/__add___0" -> "210 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/softmax_0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"210 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/softmax_0" -> "211 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/type_0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"211 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/type_0" -> "212 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Dropout[attn_dropout]/dropout_0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"212 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Dropout[attn_dropout]/dropout_0" -> "213 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/matmul_1"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"213 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/matmul_1" -> "214 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"214 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "215 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/permute_3"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"215 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/permute_3" -> "216 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/contiguous_0"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"216 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/contiguous_0" -> "217 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/view_3"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"217 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/view_3" -> "218 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_proj]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"218 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_proj]/view_0" -> "219 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_proj]/addmm_0"  [label="(128, 32) \n0 -> 1", style=solid];
"219 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_proj]/addmm_0" -> "220 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_proj]/view_1"  [label="(128, 32) \n0 -> 0", style=solid];
"220 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Conv1D[c_proj]/view_1" -> "221 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Dropout[resid_dropout]/dropout_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"221 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2Attention[attn]/Dropout[resid_dropout]/dropout_0" -> "222 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/__add___0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"222 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/__add___0" -> "223 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/NNCFLayerNorm[ln_2]/layer_norm_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"222 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/__add___0" -> "248 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/__add___1"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"223 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/NNCFLayerNorm[ln_2]/layer_norm_0" -> "224 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/NNCFLayerNorm[ln_2]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"224 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/NNCFLayerNorm[ln_2]/AsymmetricQuantizer/asymmetric_quantize_0" -> "225 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_fc]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"225 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_fc]/view_0" -> "226 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_fc]/addmm_0"  [label="(128, 32) \n0 -> 1", style=solid];
"226 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_fc]/addmm_0" -> "227 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1"  [label="(128, 128) \n0 -> 0", style=solid];
"227 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1" -> "228 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"227 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1" -> "231 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_2"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"227 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1" -> "235 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"228 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_0" -> "229 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"229 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___0" -> "230 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_1"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"230 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_1" -> "242 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"231 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_2" -> "232 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/pow_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"232 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/pow_0" -> "233 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_3"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"233 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_3" -> "234 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___1"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"234 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___1" -> "235 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0"  [label="(1, 128, 128) \n0 -> 1", style=solid];
"235 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0" -> "236 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_4"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"236 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_4" -> "237 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___2"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"237 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___2" -> "238 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_5"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"238 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_5" -> "239 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/tanh_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"239 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/tanh_0" -> "240 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__radd___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"240 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__radd___0" -> "241 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_6"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"241 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_6" -> "242 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0"  [label="(1, 128, 128) \n0 -> 1", style=solid];
"242 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0" -> "243 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_7"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"243 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_7" -> "244 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_proj]/view_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"244 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_proj]/view_0" -> "245 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_proj]/addmm_0"  [label="(128, 128) \n0 -> 1", style=solid];
"245 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_proj]/addmm_0" -> "246 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_proj]/view_1"  [label="(128, 32) \n0 -> 0", style=solid];
"246 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Conv1D[c_proj]/view_1" -> "247 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Dropout[dropout]/dropout_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"247 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/GPT2MLP[mlp]/Dropout[dropout]/dropout_0" -> "248 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/__add___1"  [label="(1, 128, 32) \n0 -> 1", style=solid];
"248 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/__add___1" -> "249 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/NNCFLayerNorm[ln_1]/layer_norm_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"248 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[3]/__add___1" -> "282 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/__add___0"  [label="(1, 128, 32) \n0 -> 1", style=solid];
"249 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/NNCFLayerNorm[ln_1]/layer_norm_0" -> "250 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/NNCFLayerNorm[ln_1]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"250 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/NNCFLayerNorm[ln_1]/AsymmetricQuantizer/asymmetric_quantize_0" -> "251 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_attn]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"251 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_attn]/view_0" -> "252 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_attn]/addmm_0"  [label="(128, 32) \n0 -> 1", style=solid];
"252 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_attn]/addmm_0" -> "253 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_attn]/view_1"  [label="(128, 96) \n0 -> 0", style=solid];
"253 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_attn]/view_1" -> "254 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/split_0"  [label="(1, 128, 96) \n0 -> 0", style=solid];
"254 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/split_0" -> "255 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"254 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/split_0" -> "258 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_1"  [label="(1, 128, 32) \n1 -> 0", style=solid];
"254 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/split_0" -> "261 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/view_2"  [label="(1, 128, 32) \n2 -> 0", style=solid];
"255 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_0" -> "256 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"256 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/view_0" -> "257 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/permute_0"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"257 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/permute_0" -> "264 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/matmul_0"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"258 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/SymmetricQuantizer/symmetric_quantize_1" -> "259 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/view_1"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"259 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/view_1" -> "260 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/permute_1"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"260 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/permute_1" -> "263 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/transpose_0"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"260 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/permute_1" -> "322 /nncf_model_output_8"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"261 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/view_2" -> "262 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/permute_2"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"262 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/permute_2" -> "273 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/matmul_1"  [label="(1, 4, 128, 8) \n0 -> 1", style=solid];
"262 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/permute_2" -> "323 /nncf_model_output_9"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"263 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/transpose_0" -> "264 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/matmul_0"  [label="(1, 4, 8, 128) \n0 -> 1", style=solid];
"264 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/matmul_0" -> "266 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/__truediv___0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"265 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/full_0" -> "266 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/__truediv___0"  [label="() \n0 -> 1", style=solid];
"266 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/__truediv___0" -> "268 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/where_0"  [label="(1, 4, 128, 128) \n0 -> 1", style=solid];
"267 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/full_1" -> "268 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/where_0"  [label="() \n0 -> 2", style=solid];
"268 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/where_0" -> "269 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/__add___0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"269 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/__add___0" -> "270 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/softmax_0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"270 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/softmax_0" -> "271 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/type_0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"271 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/type_0" -> "272 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Dropout[attn_dropout]/dropout_0"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"272 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Dropout[attn_dropout]/dropout_0" -> "273 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/matmul_1"  [label="(1, 4, 128, 128) \n0 -> 0", style=solid];
"273 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/matmul_1" -> "274 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"274 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/AsymmetricQuantizer/asymmetric_quantize_0" -> "275 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/permute_3"  [label="(1, 4, 128, 8) \n0 -> 0", style=solid];
"275 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/permute_3" -> "276 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/contiguous_0"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"276 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/contiguous_0" -> "277 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/view_3"  [label="(1, 128, 4, 8) \n0 -> 0", style=solid];
"277 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/view_3" -> "278 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_proj]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"278 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_proj]/view_0" -> "279 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_proj]/addmm_0"  [label="(128, 32) \n0 -> 1", style=solid];
"279 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_proj]/addmm_0" -> "280 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_proj]/view_1"  [label="(128, 32) \n0 -> 0", style=solid];
"280 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Conv1D[c_proj]/view_1" -> "281 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Dropout[resid_dropout]/dropout_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"281 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2Attention[attn]/Dropout[resid_dropout]/dropout_0" -> "282 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/__add___0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"282 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/__add___0" -> "283 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/NNCFLayerNorm[ln_2]/layer_norm_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"282 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/__add___0" -> "308 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/__add___1"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"283 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/NNCFLayerNorm[ln_2]/layer_norm_0" -> "284 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/NNCFLayerNorm[ln_2]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"284 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/NNCFLayerNorm[ln_2]/AsymmetricQuantizer/asymmetric_quantize_0" -> "285 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_fc]/view_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"285 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_fc]/view_0" -> "286 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_fc]/addmm_0"  [label="(128, 32) \n0 -> 1", style=solid];
"286 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_fc]/addmm_0" -> "287 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1"  [label="(128, 128) \n0 -> 0", style=solid];
"287 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1" -> "288 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"287 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1" -> "291 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_2"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"287 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_fc]/view_1" -> "295 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"288 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_0" -> "289 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"289 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___0" -> "290 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_1"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"290 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_1" -> "302 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"291 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_2" -> "292 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/pow_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"292 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/pow_0" -> "293 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_3"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"293 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_3" -> "294 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___1"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"294 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___1" -> "295 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0"  [label="(1, 128, 128) \n0 -> 1", style=solid];
"295 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__add___0" -> "296 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_4"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"296 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_4" -> "297 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___2"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"297 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__rmul___2" -> "298 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_5"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"298 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_5" -> "299 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/tanh_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"299 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/tanh_0" -> "300 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__radd___0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"300 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__radd___0" -> "301 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_6"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"301 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_6" -> "302 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0"  [label="(1, 128, 128) \n0 -> 1", style=solid];
"302 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/__mul___0" -> "303 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_7"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"303 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/NewGELUActivation[act]/AsymmetricQuantizer/asymmetric_quantize_7" -> "304 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_proj]/view_0"  [label="(1, 128, 128) \n0 -> 0", style=solid];
"304 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_proj]/view_0" -> "305 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_proj]/addmm_0"  [label="(128, 128) \n0 -> 1", style=solid];
"305 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_proj]/addmm_0" -> "306 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_proj]/view_1"  [label="(128, 32) \n0 -> 0", style=solid];
"306 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Conv1D[c_proj]/view_1" -> "307 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Dropout[dropout]/dropout_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"307 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/GPT2MLP[mlp]/Dropout[dropout]/dropout_0" -> "308 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/__add___1"  [label="(1, 128, 32) \n0 -> 1", style=solid];
"308 GPT2LMHeadModel/GPT2Model[transformer]/ModuleList[h]/GPT2Block[4]/__add___1" -> "309 GPT2LMHeadModel/GPT2Model[transformer]/NNCFLayerNorm[ln_f]/layer_norm_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"309 GPT2LMHeadModel/GPT2Model[transformer]/NNCFLayerNorm[ln_f]/layer_norm_0" -> "310 GPT2LMHeadModel/GPT2Model[transformer]/NNCFLayerNorm[ln_f]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"310 GPT2LMHeadModel/GPT2Model[transformer]/NNCFLayerNorm[ln_f]/AsymmetricQuantizer/asymmetric_quantize_0" -> "311 GPT2LMHeadModel/GPT2Model[transformer]/view_2"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"311 GPT2LMHeadModel/GPT2Model[transformer]/view_2" -> "313 GPT2LMHeadModel/NNCFLinear[lm_head]/linear_0"  [label="(1, 128, 32) \n0 -> 0", style=solid];
"312 GPT2LMHeadModel/NNCFLinear[lm_head]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "313 GPT2LMHeadModel/NNCFLinear[lm_head]/linear_0"  [label="(1000, 32) \n0 -> 1", style=solid];
"313 GPT2LMHeadModel/NNCFLinear[lm_head]/linear_0" -> "324 /nncf_model_output_10"  [label="(1, 128, 1000) \n0 -> 0", style=solid];
}
